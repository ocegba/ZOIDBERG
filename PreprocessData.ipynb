{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure, transform #scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "  \n",
    "  def __init__(self, data_dir, n_samples):\n",
    "    self.data_dir = data_dir\n",
    "    self.n_samples = n_samples\n",
    "    \n",
    "  def load_data(self, folder):\n",
    "    path = os.path.join(self.data_dir, folder)\n",
    "    files = os.listdir(path)\n",
    "    data = []\n",
    "\n",
    "    if self.n_samples is not None:\n",
    "        files = files[:self.n_samples]\n",
    "    \n",
    "    print(path)\n",
    "    num_processed = 0\n",
    "    num_total = len(files)\n",
    "    for file in files:\n",
    "        if file != '.DS_Store':\n",
    "            img_path = os.path.join(path, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "#             if len(img.shape) == 2:\n",
    "#                 # If image is grayscale, duplicate the channels to create a 3D image\n",
    "#                 img = np.expand_dims(img, axis=-1)\n",
    "#                 img = np.repeat(img, 3, axis=-1)\n",
    "\n",
    "            img = exposure.equalize_adapthist(img, clip_limit=0.05)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = img.astype('float32') / 255.0\n",
    "\n",
    "            print(img.shape) #(224, 224, 3)\n",
    "            data.append(img)\n",
    "            \n",
    "            num_processed += 1\n",
    "            print(f\"Processed image {num_processed}/{num_total}\")\n",
    "            \n",
    "            \n",
    "#     for file in files:\n",
    "#       if file != '.DS_Store':\n",
    "#         img_path = os.path.join(path, file)\n",
    "#         img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "#         img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#         img = exposure.equalize_adapthist(img, clip_limit=0.05)\n",
    "#         img = cv2.resize(img, (224, 224))\n",
    "\n",
    "#         img = img.astype('float32') / 255.0\n",
    "\n",
    "#         print(img.shape)\n",
    "#         data.append(img)\n",
    "        \n",
    "#         num_processed += 1\n",
    "#         print(f\"Processed image {num_processed}/{num_total}\")\n",
    "    \n",
    "    a = np.array(data)\n",
    "    print(np.shape(a))\n",
    "    return a\n",
    "\n",
    "  def preprocess(self):\n",
    "    train_normal = self.load_data('train/NORMAL')\n",
    "    train_pneumonia = self.load_data('train/PNEUMONIA')\n",
    "    print(\"np.shape(train_normal)\", np.shape(train_normal))\n",
    "    print(\"np.shape(train_pneumonia)\", np.shape(train_pneumonia))\n",
    "\n",
    "    test_normal = self.load_data('test/NORMAL')\n",
    "    test_pneumonia = self.load_data('test/PNEUMONIA')\n",
    "    \n",
    "    val_normal = self.load_data('val/NORMAL')\n",
    "    val_pneumonia = self.load_data('val/PNEUMONIA')\n",
    "    print(\"np.shape(val_normal)\", np.shape(val_normal))\n",
    "    print(\"np.shape(test_pneumonia)\", np.shape(test_pneumonia))\n",
    "    \n",
    "    return train_normal, train_pneumonia, test_normal, test_pneumonia, val_normal, val_pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
