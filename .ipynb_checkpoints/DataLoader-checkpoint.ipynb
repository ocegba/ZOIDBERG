{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da4c3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from ipynb.fs.full.DataGenerator import DataGenerator\n",
    "from ipynb.fs.full.PreprocessData import Preprocessing\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261218ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, samplesTrain, samplesVal, samplesTest, batch_size=64, augment_data=True, shuffle=True):\n",
    "        self.samplesTrain = samplesTrain\n",
    "        self.samplesVal = samplesVal\n",
    "        self.samplesTest = samplesTest\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.augment_data = augment_data\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "        self.test_data = None\n",
    "        \n",
    "        self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        preprocess_files = Preprocessing(\"input\", self.samplesTrain, self.samplesVal, self.samplesTest)\n",
    "        train_normal, train_pneumonia, test_normal, test_pneumonia, val_normal, val_pneumonia = preprocess_files.preprocess()\n",
    "        \n",
    "        self.train_data = self.load_train_data(train_normal, train_pneumonia)\n",
    "        self.val_data = self.load_val_data(test_normal, test_pneumonia)\n",
    "        self.test_data = self.load_test_data(val_normal, val_pneumonia)\n",
    "\n",
    "    def load_train_data(self, train_normal, train_pneumonia):\n",
    "        \"\"\"\n",
    "        retourne un tableau d'images en utilisant les train_normal et train_pneumonia dont les étiquettes sont respectivement\n",
    "        0 et 1 lorsque NORMAL et PNEUMONIA concaténées\n",
    "        np.shape(train_normal) ===> (224, 224, 3)\n",
    "        np.shape(train_pneumonia) ===> (224, 224, 3)\n",
    "        \"\"\"\n",
    "        X = np.concatenate((train_normal, train_pneumonia))\n",
    "        y = np.concatenate((np.zeros(train_normal.shape[0]), np.ones(train_pneumonia.shape[0])))\n",
    "        return (X, y)\n",
    "    \n",
    "    def load_val_data(self, val_normal, val_pneumonia):\n",
    "        \"\"\"\n",
    "        retourne un tableau d'images val_normal et val_pneumonia dont les étiquettes sont NORMAL et PNEUMONIA concaténées\n",
    "        \"\"\"\n",
    "        X = np.concatenate((val_normal, val_pneumonia))\n",
    "        y = np.concatenate((np.zeros(val_normal.shape[0]), np.ones(val_pneumonia.shape[0])))\n",
    "        return (X, y)\n",
    "    \n",
    "    def load_test_data(self, test_normal, test_pneumonia):\n",
    "        \"\"\"\n",
    "        retourne un tableau d'images test_normal et test_pneumonia dont les étiquettes sont NORMAL et PNEUMONIA concaténées\n",
    "        \"\"\"\n",
    "        X = np.concatenate((test_normal, test_pneumonia))\n",
    "        y = np.concatenate((np.zeros(test_normal.shape[0]), np.ones(test_pneumonia.shape[0])))\n",
    "        return (X, y)\n",
    "    \n",
    "    def load_train_generator(self):\n",
    "        return DataGenerator(*self.train_data,\n",
    "                             batch_size=self.samplesTrain,\n",
    "                             shuffle=self.shuffle,\n",
    "                             augment_data=self.augment_data\n",
    "                            )\n",
    "\n",
    "    def load_validation_generator(self):\n",
    "        return DataGenerator(*self.val_data,\n",
    "                             batch_size=self.samplesVal,\n",
    "                             shuffle=False,\n",
    "                             augment_data=False\n",
    "                            )\n",
    "    \n",
    "    def load_test_generator(self):\n",
    "        return DataGenerator(*self.test_data,\n",
    "                             batch_size=self.samplesTest,\n",
    "                             shuffle=False,\n",
    "                             augment_data=False\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e002f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "input\\train/NORMAL\n",
      "Processed image 1/5\n",
      "Processed image 2/5\n",
      "Processed image 3/5\n",
      "Processed image 4/5\n",
      "############################################################################################\n",
      "input\\train/PNEUMONIA\n",
      "Processed image 1/5\n",
      "Processed image 2/5\n",
      "Processed image 3/5\n",
      "Processed image 4/5\n",
      "############################################################################################\n",
      "input\\test/NORMAL\n",
      "Processed image 1/2\n",
      "Processed image 2/2\n",
      "############################################################################################\n",
      "input\\test/PNEUMONIA\n",
      "Processed image 1/2\n",
      "Processed image 2/2\n",
      "############################################################################################\n",
      "input\\val/NORMAL\n",
      "Processed image 1/3\n",
      "Processed image 2/3\n",
      "############################################################################################\n",
      "input\\val/PNEUMONIA\n",
      "Processed image 1/3\n",
      "Processed image 2/3\n"
     ]
    }
   ],
   "source": [
    "# data_loader = DataLoader(samplesTrain= 5,\n",
    "#                          samplesVal=3,\n",
    "#                          samplesTest= 2,\n",
    "#                          batch_size=64,\n",
    "#                          augment_data=True,\n",
    "#                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504bf27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len de X : 8\n",
      "len de X : 4\n",
      "len de X : 4\n"
     ]
    }
   ],
   "source": [
    "# train_data = data_loader.load_train_generator()\n",
    "# val_data   = data_loader.load_validation_generator()\n",
    "# test_data  = data_loader.load_test_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b10aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "images 10\n",
      "4\n",
      "images 6\n",
      "4\n",
      "images 4\n"
     ]
    }
   ],
   "source": [
    "# train_X, train_y = train_data[0]\n",
    "# val_X, val_y = val_data[0]\n",
    "# test_X, test_y = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94f37ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# print(len(train_X), len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f781a1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "# print(len(val_X), len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f2d991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "# print(len(test_X), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65a0f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipynb.fs.full.DataGenerator.DataGenerator object at 0x000001C65DCA7D30>\n"
     ]
    }
   ],
   "source": [
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bed8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe764aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_X, train_y = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "963b3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "781e159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
